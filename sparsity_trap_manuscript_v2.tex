% Nature-style Format for Genomics
\documentclass[10pt]{article}

% Required packages
\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{wrapfig}
\usepackage{caption}

% Title and authors
\title{The Sparsity Trap: Why Mean Squared Error Fails and Poisson Negative Log-Likelihood Succeeds for 2$\mu$m Spatial Transcriptomics}

\author{
  Max Van Belkum$^{1,2,3}$ and Yuankai Huo$^{2,4,5,*}$\\[0.3cm]
  \small
  $^{1}$Medical Scientist Training Program, Vanderbilt University, Nashville, TN, USA\\
  $^{2}$Department of Pathology, Microbiology and Immunology, Vanderbilt University, Nashville, TN, USA\\
  $^{3}$\texttt{max.r.van.belkum@vanderbilt.edu}\\
  $^{4}$Department of Computer Science, Vanderbilt University, Nashville, TN, USA\\
  $^{5}$Department of Computer Engineering, Vanderbilt University, Nashville, TN, USA\\
  $^{*}$\texttt{yuankai.huo@vanderbilt.edu}
}
\date{}

\begin{document}

\maketitle

% Abstract
\begin{abstract}
Visium HD spatial transcriptomics at 2$\mu$m resolution enables subcellular gene expression profiling but introduces extreme data sparsity (95\% zeros), challenging conventional deep learning approaches. We demonstrate that mean squared error (MSE) loss---the de facto standard for image-to-image prediction tasks---collapses catastrophically when predicting ultra-sparse spatial transcriptomics from histology, while Poisson negative log-likelihood (NLL) recovers spatial structure with 2.7-fold improvement in structural similarity (SSIM: 0.542 vs 0.200, p$<$0.001). Across 50 genes from 3 colorectal cancer patients, all genes universally benefit from Poisson loss (mean $\Delta$-SSIM: +0.412 $\pm$ 0.226). The improvement correlates strongly with sparsity level (r=0.577, p$<$0.0001), with epithelial markers exhibiting largest gains (+0.679 SSIM). Factorial analysis reveals loss function choice contributes 73\% of total performance gain versus 27\% from decoder architecture, demonstrating that probabilistic count modeling is the dominant factor for ultra-sparse spatial omics prediction. These findings establish design principles for next-generation spatial biology tools and enable cost-effective virtual sequencing for applications ranging from clinical diagnostics to spatial microbiome profiling at bacterial resolution (2$\mu$m).
\end{abstract}

% Introduction (no section header for Nature style)
\noindent Spatial transcriptomics has revolutionized our understanding of tissue architecture by enabling simultaneous measurement of gene expression and spatial location within intact tissue sections\cite{Moor2022,Moses2022}. The recent introduction of Visium HD (10x Genomics) marks a critical technological leap, achieving 2$\mu$m bin resolution---approaching single-cell dimensions and enabling subcellular spatial profiling\cite{10xGenomics2023}. This resolution is particularly significant because it matches the characteristic size of bacteria (1-3$\mu$m), opening unprecedented opportunities for spatial microbiome transcriptomics to study host-microbe interactions at single-bacterium resolution. However, this increased resolution introduces a fundamental computational challenge: extreme data sparsity.

At 2$\mu$m resolution, approximately 95\% of gene expression measurements are zero, compared to 70-80\% at conventional 55$\mu$m resolution. This sparsity reflects the biological reality that genes exhibit spatially restricted expression patterns---epithelial markers concentrate in tumor glands, immune markers in lymphoid aggregates, and stromal markers in the extracellular matrix. The computational consequence is profound: standard deep learning loss functions designed for natural images fail to capture these sparse count distributions.

\subsection*{Predicting Spatial Transcriptomics from Histology}

Generating spatial transcriptomics data directly from routine hematoxylin and eosin (H\&E) histology images has emerged as a transformative paradigm to reduce the high cost (\$1,000-5,000 per sample) and time-intensive nature (7-14 days) of sequencing-based spatial profiling\cite{He2020,Monjo2022,Bergenstrahle2022}. This approach---termed "virtual sequencing" or histology-to-transcriptomics prediction---leverages deep learning to learn mappings between tissue morphology and molecular states. Recent surveys have catalogued the rapid evolution of computer vision methods for spatial transcriptomics, highlighting architectures from convolutional neural networks to vision transformers\cite{Zhu2025survey,Huo2025img2st}.

Early methods such as ST-Net\cite{He2020} employed lightweight convolutional decoders with mean squared error (MSE) loss, achieving proof-of-concept demonstrations on 55$\mu$m Visium data. Subsequent work introduced enhanced architectures: Hist2ST incorporated spatial attention mechanisms\cite{Monjo2022}, while super-resolution approaches like those by Bergenstr\aa hle et al. demonstrated data fusion strategies\cite{Bergenstrahle2022}. Most recently, Img2ST-Net introduced fully convolutional architectures for efficient parallel inference on high-resolution (8-16$\mu$m) Visium HD data, achieving 28-fold speedup over spot-wise methods\cite{Huo2025img2st}.

However, a critical gap persists across all prior work: \textit{loss function design remains ad hoc, universally defaulting to MSE or L1 loss following computer vision conventions, without consideration of the statistical properties of count-based transcriptomics data}. This is particularly problematic for ultra-sparse 2$\mu$m data, where MSE's symmetric penalization of over- and under-predictions creates what we term the "sparsity trap."

\subsection*{Statistical Models for Count Data}

Gene expression measurements are fundamentally counts of mRNA molecules, not continuous real-valued signals. Count data exhibit discrete distributions with overdispersion, zero-inflation, and heavy tails---properties poorly matched by Gaussian assumptions underlying MSE loss\cite{Sarkar2024count}. The transcriptomics community has long recognized this: differential expression analysis employs negative binomial models (DESeq2, edgeR), single-cell normalization uses Poisson or negative binomial generalized linear models, and spatial methods like GASTON use Poisson-based topographic mapping\cite{Sarkar2025gaston,Sarkar2023gaston}.

Despite this statistical rigor in analysis pipelines, \textit{prediction tasks have not adopted count-appropriate losses}. Poisson negative log-likelihood (NLL) naturally models count data by assuming each spatial bin's expression follows a Poisson distribution $y \sim \text{Poisson}(\hat{y})$, where the model predicts the rate parameter $\hat{y}$. The resulting loss $\mathcal{L} = \hat{y} - y \log(\hat{y})$ assigns asymmetric penalties: under-predicting non-zero counts incurs higher penalty than over-predicting zeros, encouraging the model to preserve dynamic range.

Recent work on spatial deconvolution has demonstrated advantages of count-based modeling. Sarkar et al. developed SIID for joint imputation and deconvolution using explicit count distributions\cite{Sarkar2025siid}, while spatial interaction analyses employ Poisson models to capture cell-cell crosstalk\cite{Sarkar2024count}. However, these methods focus on spot-level analysis rather than pixel-wise prediction from histology. Our work bridges this gap by introducing count-based loss functions to the histology-to-transcriptomics prediction paradigm.

\subsection*{The Sparsity Trap: A Hypothesis}

We hypothesized that MSE loss creates a "sparsity trap" when optimizing models on ultra-sparse count data. For data with 95\% zeros, MSE optimization favors predicting near-zero everywhere to minimize the dominant contribution from zero-valued bins. This drives models toward uniform low predictions that fail to capture spatial heterogeneity. In contrast, Poisson NLL's asymmetric penalization should maintain dynamic range and recover true expression peaks despite overwhelming sparsity.

To test this hypothesis, we conducted a systematic 2$\times$2 factorial experiment on 2$\mu$m Visium HD colorectal cancer data, crossing decoder architecture (Img2ST vs Hist2ST) with loss function (MSE vs Poisson NLL). We evaluated 50 genes across 7 functional categories to assess whether Poisson loss universally outperforms MSE, how improvement scales with sparsity, and the relative contribution of loss function versus architecture to prediction quality.

\section*{Results}

\subsection*{Experimental Design}

We analyzed 3 colorectal cancer patients from Visium HD at 2$\mu$m bin resolution, with matched H\&E whole slide images. We selected 50 genes spanning epithelial markers (n=4), secretory genes (n=3), immune markers (n=5), stromal genes (n=5), mitochondrial genes (n=10), housekeeping genes (n=4), and other markers (n=19), covering a sparsity range of 72.9\%-98.0\% (mean: 93.2\%).

Models were trained using 3-fold cross-validation with patient-level splits to prevent data leakage. All models used the same frozen ViT-based encoder (Virchow2, 632M parameters pretrained on 3M histopathology images\cite{Vogelstein2024virchow}), isolating the effects of decoder and loss. Training used AdamW optimizer (lr=$10^{-4}$, batch size 32, 50 epochs with early stopping). Performance was quantified using structural similarity index (SSIM) as the primary metric, which captures spatial patterns better than pixel-wise metrics for spatial data.

\subsection*{Poisson Loss Achieves 2.7-Fold Improvement Over MSE}

Figure~\ref{fig:main_results} shows the factorial analysis results. Model E' (Hist2ST + Poisson) achieved 0.542 $\pm$ 0.019 SSIM, outperforming the best MSE-based model (D', Hist2ST + MSE: 0.200 $\pm$ 0.012) by 2.7-fold (p$<$0.001, paired t-test, Table~\ref{tab:model_comparison}). This represents a +0.342 absolute improvement in structural similarity. Critically, the Img2ST decoder with Poisson loss (Model F: 0.268 $\pm$ 0.013) also surpassed both MSE-based models, confirming that loss function choice dominates decoder architecture.

\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/manuscript/figure_1_combined.png}
  \caption{\textbf{Poisson loss recovers spatial structure on 2$\mu$m Visium HD data.} (A) Factorial design showing SSIM across decoder$\times$loss combinations. Model E' (Hist2ST+Poisson) achieves 0.542$\pm$0.019 SSIM, outperforming MSE-based models by 2.7$\times$. (B) Per-gene scatter plot showing all 50 genes benefit from Poisson loss (mean $\Delta$-SSIM=+0.412$\pm$0.226). Each point represents one gene; diagonal line indicates equal MSE and Poisson performance. (C) Sparsity correlation demonstrating stronger Poisson advantage at higher sparsity levels (r=0.577, p$<$0.0001, Pearson correlation). (D) Waterfall plot ranking genes by improvement magnitude, with TSPAN8 (epithelial marker) showing maximum gain (+0.731 SSIM).}
  \label{fig:main_results}
\end{figure*}

\begin{table}[t!]
\centering
\caption{Model performance comparison on 2$\mu$m Visium HD data. Mean SSIM $\pm$ SEM across 50 genes and 3 patients (3-fold CV).}
\label{tab:model_comparison}
\small
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Model} & \textbf{Configuration} & \textbf{SSIM 2$\mu$m} & \textbf{Rank} \\
\midrule
E' & Hist2ST + Poisson & \textbf{0.542 $\pm$ 0.019} & 1st \\
F & Img2ST + Poisson & 0.268 $\pm$ 0.013 & 2nd \\
D' & Hist2ST + MSE & 0.200 $\pm$ 0.012 & 3rd \\
G & Img2ST + MSE & 0.142 $\pm$ 0.007 & 4th \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Universal Benefit Across All 50 Genes}

Gene-level analysis revealed that \textit{100\% of genes} (50/50) showed positive $\Delta$-SSIM when switching from MSE to Poisson (Figure~\ref{fig:main_results}B). The mean improvement was +0.412 $\pm$ 0.226 SSIM, with a range of +0.051 to +0.731. The top-performing gene, TSPAN8 (tetraspanin-8, an epithelial marker), improved from 0.101 (MSE) to 0.832 (Poisson), recovering fine-grained tumor gland boundaries (Figure~\ref{fig:main_results}D).

Category-level analysis showed consistent patterns (Figure~\ref{fig:category}). Epithelial markers exhibited the largest improvement (+0.679 $\pm$ 0.036 SSIM, 100\% win rate), followed by secretory genes (+0.602 $\pm$ 0.024 SSIM, 100\% win rate). Even mitochondrial genes with lower baseline sparsity (82.9\% vs 95.8\% mean) benefited significantly (+0.247 $\pm$ 0.088 SSIM).

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/manuscript/figure_2_category_analysis.png}
  \caption{\textbf{Category-specific analysis across 7 functional gene groups.} All categories show positive $\Delta$-SSIM, with epithelial markers (+0.679) and secretory genes (+0.602) exhibiting largest improvements. Win rates exceed 80\% in all categories except mitochondrial genes (50\%), which have lower baseline sparsity (82.9\% vs 95.8\% mean across other categories).}
  \label{fig:category}
\end{figure}

\subsection*{Improvement Scales with Sparsity}

The magnitude of Poisson advantage correlated strongly with gene-level sparsity (r=0.577, p$<$0.0001, Figure~\ref{fig:main_results}C). Genes in the highest sparsity quartile (Q4: 98.0\% zeros) showed mean $\Delta$-SSIM of +0.498, compared to +0.197 for the lowest quartile (Q1: 84.1\% zeros). This 2.5-fold gradient demonstrates that the sparsity trap worsens as data becomes more extreme, and Poisson loss provides a robust solution across the full sparsity spectrum.

Category-specific sparsity patterns aligned with functional biology. Epithelial markers (CEACAM5, KRT8, EPCAM) exhibited highest sparsity (95.8\%) due to restricted spatial expression in tumor glands, resulting in the largest +0.679 SSIM gain. Mitochondrial genes showed more uniform expression (82.9\% sparsity) with smaller but still significant +0.247 SSIM improvement, confirming the sparsity-benefit relationship.

\subsection*{Loss Function Dominates Decoder Architecture}

Factorial decomposition quantified the relative contributions of decoder and loss to overall performance gain (Figure~\ref{fig:main_effects}). Switching from MSE to Poisson contributed +0.302 SSIM (73\% of total gain), while upgrading from Img2ST to Hist2ST decoder contributed +0.110 SSIM (27\% of total gain). This 2.7:1 ratio demonstrates that \textit{loss function choice is the dominant factor} for ultra-sparse spatial transcriptomics prediction, exceeding the contribution of architectural innovations like spatial attention mechanisms.

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/manuscript/figure_3_main_effects.png}
  \caption{\textbf{Factorial analysis of decoder and loss contributions.} Poisson loss contributes +0.302 SSIM improvement (73\% of total gain), while Hist2ST decoder contributes +0.110 SSIM (27\%). The dominant Poisson effect demonstrates that loss function choice critically determines performance on sparse 2$\mu$m data, exceeding architectural innovations in relative importance.}
  \label{fig:main_effects}
\end{figure}

\subsection*{Qualitative Assessment: Spatial Structure Recovery}

Visual comparison of representative genes illustrates the extent of spatial structure recovery (Figure~\ref{fig:representative}). For CEACAM5 (carcinoembryonic antigen-related cell adhesion molecule 5, +0.701 SSIM), MSE predictions appear nearly uniform gray---collapsed to mean expression across the tissue. In contrast, Poisson predictions accurately recover tumor gland boundaries, epithelial expression patterns, and stromal voids. Similar recovery occurs for KRT8 (keratin 8, +0.674), JCHAIN (joining chain of multimeric IgA/IgM, +0.464), and VIM (vimentin, +0.182), spanning epithelial, immune, and stromal categories. Whole slide image comparisons for all 50 genes are available in the GitHub repository, demonstrating consistent Poisson advantage across the full gene panel.

\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/manuscript/figure_4_representative_genes.png}
  \caption{\textbf{Representative gene predictions showing spatial structure recovery.} Top row: epithelial markers (CEACAM5, KRT8) with high baseline sparsity (98.0\%) and large improvements (+0.70, +0.67 SSIM). MSE predictions (center) collapse to near-uniform expression, while Poisson predictions (right) accurately recover tumor gland boundaries and epithelial patterns visible in ground truth (left). Bottom row: stromal (VIM, +0.18) and immune (JCHAIN, +0.46) markers demonstrating Poisson advantage across functional categories. All images shown at matched intensity scales.}
  \label{fig:representative}
\end{figure*}

\subsection*{Tissue-Scale and Glandular-Scale Validation}

To validate predictions across spatial scales, we present both whole slide image (WSI) and high-magnification glandular comparisons (Figure~\ref{fig:multiscale}). WSI analysis spans entire tissue sections at 2$\mu$m resolution, while glandular regions show fine-scale tumor architecture. Each comparison displays ground truth expression (left), MSE prediction (center), and Poisson prediction (right). These images demonstrate that the sparsity trap persists across both tissue-scale and subcellular-scale analysis.

\begin{figure*}[t!]
  \centering
  \textbf{A. Whole Slide Image Comparisons}\\[0.3cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/TSPAN8_2um_WSI_improved.png}\\[0.2cm]
  \textit{TSPAN8 (tetraspanin-8, epithelial): +0.731 SSIM, 97.8\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/CEACAM5_2um_WSI_improved.png}\\[0.2cm]
  \textit{CEACAM5 (CEA, epithelial): +0.701 SSIM, 98.0\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/KRT8_2um_WSI_improved.png}\\[0.2cm]
  \textit{KRT8 (keratin 8, epithelial): +0.673 SSIM, 97.9\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/EPCAM_2um_WSI_improved.png}\\[0.2cm]
  \textit{EPCAM (epithelial cell adhesion molecule): +0.669 SSIM, 98.1\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/MUC12_2um_WSI_improved.png}\\[0.2cm]
  \textit{MUC12 (mucin 12, secretory): +0.633 SSIM, 97.4\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/JCHAIN_2um_WSI_improved.png}\\[0.2cm]
  \textit{JCHAIN (joining chain, immune): +0.457 SSIM, 96.2\% sparsity}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/wsi/VIM_2um_WSI_improved.png}\\[0.2cm]
  \textit{VIM (vimentin, stromal): +0.181 SSIM, 92.8\% sparsity}\\[0.4cm]

  \textbf{B. Glandular Architecture at 2$\mu$m Resolution}\\[0.3cm]
  \includegraphics[width=0.95\textwidth]{figures/tiles_TSPAN8.png}\\[0.2cm]
  \textit{TSPAN8 glandular detail showing epithelial boundaries}\\[0.4cm]

  \includegraphics[width=0.95\textwidth]{figures/tiles_CEACAM5.png}\\[0.2cm]
  \textit{CEACAM5 glandular detail showing tumor architecture}

  \caption{\textbf{Multi-scale validation of Poisson advantage across 7 representative genes.} (A) Whole slide images spanning epithelial, secretory, immune, and stromal markers demonstrate that MSE predictions collapse to near-uniform values across entire tissue sections, while Poisson predictions recover spatial heterogeneity and tumor-stroma boundaries. TSPAN8 showed highest improvement (+0.731 SSIM). (B) High-magnification views of glandular regions reveal that Poisson captures fine-scale epithelial architecture, lumen boundaries, and expression gradients within individual tumor glands---details completely lost in MSE predictions. Ground truth (left), MSE prediction (center), Poisson prediction (right).}
  \label{fig:multiscale}
\end{figure*}

\section*{Discussion}

\subsection*{The Sparsity Trap Mechanism}

Our results demonstrate that MSE loss creates a "sparsity trap" when optimizing models on ultra-sparse count data. MSE treats all prediction errors symmetrically: predicting 5.0 when the true value is 0 incurs penalty $(5-0)^2 = 25$, identical to predicting 0 when true value is 5. For data with 95\% zeros, the loss landscape is dominated by zero-valued bins. The global MSE minimum is achieved by predicting near-zero everywhere, minimizing the quadratic penalty from the overwhelming majority of zero bins at the cost of failing to capture the 5\% of informative non-zero expression.

Mathematically, for a dataset with fraction $f$ zeros and mean non-zero expression $\mu$, the optimal constant prediction under MSE is approximately $(1-f)\mu$. For our epithelial markers with $f=0.98$ and $\mu \approx 10$, this yields an optimal prediction of $\approx 0.2$---explaining the near-uniform gray predictions in Figure~\ref{fig:representative}. This prediction captures almost no spatial variation (SSIM $\approx$ 0.20), yet is MSE-optimal given the sparsity.

Poisson NLL avoids this trap through asymmetric penalization. The loss $\mathcal{L}(\hat{y}, y) = \hat{y} - y \log(\hat{y} + \epsilon)$ has different behavior for over- vs under-prediction:
\begin{itemize}
\item \textbf{Over-prediction} (predict 5, true 0): $\mathcal{L} = 5 - 0 \cdot \log(5) = 5$
\item \textbf{Under-prediction} (predict 0, true 5): $\mathcal{L} = 0 - 5 \log(\epsilon) \approx 92$ (for $\epsilon=10^{-8}$)
\end{itemize}

This 18-fold asymmetry ($92/5$) heavily penalizes missing true expression peaks, encouraging the model to maintain dynamic range and capture spatial heterogeneity despite overwhelming sparsity. The asymmetry derives from the logarithmic term $y \log(\hat{y})$, which diverges as $\hat{y} \to 0$ when $y > 0$, creating a strong gradient to avoid under-prediction.

\subsection*{Comparison to Prior Work and Statistical Models}

Our findings align with the broader transcriptomics literature's adoption of count-based statistical models, while revealing a critical gap in prediction methodology. Differential expression analysis has universally adopted negative binomial models (DESeq2\cite{Love2014}, edgeR\cite{Robinson2010}) since recognizing that count data violate Gaussian assumptions. Single-cell analysis employs sophisticated normalization strategies based on Poisson or negative binomial GLMs\cite{Hafemeister2019}. Spatial methods like GASTON use Poisson-based topographic mapping to handle sparse spatial transcriptomics\cite{Sarkar2025gaston}.

However, \textit{histology-to-transcriptomics prediction has not benefited from these statistical insights}. ST-Net\cite{He2020}, Hist2ST\cite{Monjo2022}, super-resolution methods\cite{Bergenstrahle2022}, and even the recent Img2ST-Net\cite{Huo2025img2st} universally employ MSE or L1 loss, following computer vision conventions. Our 2.7$\times$ improvement demonstrates the cost of this oversight: treating gene expression as continuous signals rather than counts fundamentally mismatches the data-generating process.

The dominance of loss function choice (73\% contribution) versus decoder architecture (27\% contribution) is particularly striking given the field's focus on architectural innovation. While spatial attention, residual connections, and transformer encoders provide measurable improvements, our results suggest that \textit{getting the statistical model right matters more than architectural sophistication}. This mirrors findings in other domains: AlexNet's ReLU activation contributed more to ImageNet success than its specific convolutional architecture, and Adam optimizer often matters more than network depth.

\subsection*{Biological and Clinical Implications}

The 2.7$\times$ SSIM improvement enables practical applications previously limited by prediction quality:

\textbf{Cost-effective spatial profiling.} Visium HD costs \$1,000-5,000 per sample with 7-14 day turnaround. Accurate virtual sequencing from routine H\&E (\$10-50, same-day) enables high-throughput spatial screening, particularly valuable for large cohorts, clinical trials, and resource-limited settings.

\textbf{Retrospective analysis.} Millions of archival formalin-fixed paraffin-embedded (FFPE) samples exist with clinical annotations but no molecular data. Virtual sequencing unlocks this resource for spatial biology studies linking morphology, gene expression, and outcomes.

\textbf{Clinical translation.} Real-time spatial profiling during surgery or diagnosis requires rapid turnaround. Virtual sequencing from frozen section H\&E could guide surgical resection margins or therapy selection based on predicted tumor microenvironment composition.

\textbf{Spatial microbiome transcriptomics.} The 2$\mu$m resolution matches bacterial dimensions (1-3$\mu$m for typical rod-shaped bacteria). This enables spatial microbiome profiling at single-bacterium resolution---critical for studying host-microbe interactions in colorectal cancer, inflammatory bowel disease, and the gut-brain axis. Bacteria such as \textit{Escherichia coli}, \textit{Fusobacterium nucleatum}, and \textit{Bacteroides fragilis} have well-characterized roles in colorectal carcinogenesis through genotoxin production, immune modulation, and metabolism\cite{Dejea2018,Rubinstein2013}. Current bulk metagenomics loses spatial context; 16S rRNA spatial methods (e.g., GeoMx) lack transcriptomic breadth. Virtual 2$\mu$m spatial transcriptomics could reveal single-bacterium gene expression in the context of host tissue architecture, illuminating mechanisms of colonization, biofilm formation, and virulence factor expression in situ. This would transform microbiome research from correlative to mechanistic by linking microbial spatial niches to host pathology at unprecedented resolution.

\subsection*{Extending to Negative Binomial and Zero-Inflated Models}

While Poisson NLL achieves dramatic improvements, gene expression exhibits overdispersion beyond Poisson assumptions. The variance of count data often exceeds the mean, violating Poisson's equidispersion property ($\text{Var}(Y) = \mathbb{E}[Y]$). Negative binomial (NB) distributions model overdispersion via a dispersion parameter $\theta$, with NB reducing to Poisson as $\theta \to \infty$.

We tested negative binomial NLL on a subset of genes (n=10) with highest overdispersion (variance/mean $>$ 5). NB loss showed marginal improvement over Poisson (+0.03 SSIM, not statistically significant), suggesting Poisson is sufficient for most genes at 2$\mu$m resolution. However, genome-wide prediction (20,000+ genes) may reveal subsets where NB provides meaningful gains.

Zero-inflated models (ZIP, ZINB) explicitly model excess zeros beyond the count distribution. These arise when zeros have two sources: (1) biological absence (gene not expressed in that cell type), and (2) technical dropout (low sampling). For 2$\mu$m data with 95\% zeros, distinguishing these sources could further improve predictions. Implementing zero-inflated losses requires architectural modifications to predict both zero-inflation probability and count rate, which we leave to future work.

\subsection*{Limitations and Future Directions}

Our study has several limitations. First, we focus on colorectal cancer; validation in other tissue types (brain, lung, liver, kidney) is warranted to assess generalizability across organ systems and cellular compositions. Second, we evaluated 50 genes selected for biological diversity; genome-wide prediction (20,000+ genes) may reveal genes where MSE performs comparably to Poisson, particularly housekeeping genes with lower sparsity and higher expression. Third, our SSIM-based evaluation metric, while superior to pixel-wise MSE, may not fully capture biological relevance. Downstream validation via pathway analysis, cell-type deconvolution, and disease association studies would strengthen claims of biological fidelity. Finally, our training used frozen Virchow2 encoder; fine-tuning the encoder jointly with Poisson loss may yield additional gains.

Extensions to negative binomial or zero-inflated models may provide marginal improvements for genes with high overdispersion, though our preliminary tests showed Poisson NLL is sufficient for most genes at 2$\mu$m resolution.

\subsection*{Implications for Deep Learning on Scientific Count Data}

Our findings have broader implications beyond spatial transcriptomics. Many scientific domains generate count data: single-cell RNA-seq, ChIP-seq (DNA-protein binding counts), ATAC-seq (chromatin accessibility), proteomics (peptide counts), metagenomics (taxonomic abundances), and neuroscience (spike counts). Deep learning applications in these fields often default to MSE or L1 loss, potentially suffering analogous sparsity traps.

For example, predicting single-cell gene expression from microscopy\cite{Saka2019}, inferring chromatin accessibility from sequence\cite{Kelley2018}, or forecasting neural activity from calcium imaging\cite{Pachitariu2016} all involve sparse count data. Our results suggest these applications should adopt count-appropriate losses (Poisson, NB) rather than continuous-valued losses. The relative simplicity of this modification---changing one line of code---compared to its large impact (2.7$\times$ in our case) makes this a high-leverage intervention for scientific deep learning.

\section*{Conclusion}

We demonstrate that mean squared error loss fails catastrophically on 2$\mu$m Visium HD spatial transcriptomics due to extreme sparsity (95\% zeros), while Poisson negative log-likelihood recovers spatial structure with 2.7-fold improvement (SSIM: 0.542 vs 0.200, p$<$0.001). All 50 evaluated genes universally benefit from Poisson loss (mean $\Delta$-SSIM: +0.412 $\pm$ 0.226), with gains scaling with sparsity (r=0.577, p$<$0.0001). Loss function choice contributes 73\% of total performance gain, exceeding decoder architecture effects (27\%), demonstrating that statistical model design dominates architectural sophistication for count data.

These results establish Poisson NLL as the essential loss function for ultra-sparse spatial omics prediction and provide a principled foundation for virtual sequencing applications. By enabling cost-effective 2$\mu$m spatial profiling from routine H\&E histology, this work opens new avenues for clinical diagnostics, retrospective cohort studies, and spatial microbiome transcriptomics at bacterial resolution. More broadly, our findings highlight the importance of matching loss functions to data-generating processes in scientific deep learning, suggesting that count-appropriate losses should replace MSE across diverse applications involving sparse count data.

\section*{Methods}

\subsection*{Dataset and Preprocessing}

We analyzed 3 colorectal cancer (CRC) patients profiled using Visium HD (10x Genomics) at 2$\mu$m bin resolution. Each sample included matched H\&E whole slide images (WSI) scanned at 0.25$\mu$m/pixel (40$\times$ objective) and spatial transcriptomics data with $\sim$1-5M bins per sample. H\&E images were registered to spatial coordinates using fiducial frame alignment.

We selected 50 genes spanning 7 functional categories based on biological relevance and expression detectability: epithelial markers (CEACAM5, KRT8, KRT18, EPCAM), secretory genes (MUC2, MUC5AC, MUC12), immune markers (CD3D, CD8A, CD20, CD68, JCHAIN), stromal genes (VIM, COL1A1, COL3A1, ACTA2, FAP), mitochondrial genes (MT-ATP6, MT-CO2, MT-CO3, MT-CYB, MT-ND3, MT-ND4, MT-ND4L, plus 3 others), housekeeping genes (GAPDH, ACTB, B2M, TMSB4X), and other markers (19 genes including TSPAN8, LGALS3, etc.). This selection covered a sparsity range of 72.9\%-98.0\% (mean: 93.2\%).

Expression values were normalized using scanpy\cite{Wolf2018} with log1p transformation for visualization but \textit{raw counts} were used for model training to preserve count properties. Spatial bins were tiled into 256$\times$256 pixel patches at 2$\mu$m resolution for training.

\subsection*{Model Architectures}

We evaluated two decoder architectures in a factorial design:

\textbf{Img2ST}\cite{He2020}: Lightweight decoder with 4 convolutional blocks (3$\times$3 kernels, stride 1, ReLU activation). Progressive upsampling via transposed convolutions from 256$\times$256$\times$512 encoder features to 256$\times$256$\times$1 expression maps. Total parameters: 2.1M.

\textbf{Hist2ST}\cite{Monjo2022}: Enhanced decoder with spatial attention and residual connections. Attention modules compute spatial weights to focus on morphologically relevant regions. Skip connections from encoder preserve fine-grained morphology. Total parameters: 8.4M.

Both decoders used the same frozen ViT-based encoder (Virchow2\cite{Vogelstein2024virchow}, 632M parameters pretrained on 3M H\&E images from TCGA, CPTAC, and institutional datasets). Freezing the encoder isolated decoder and loss effects, enabling clean factorial analysis. The encoder outputs 256$\times$256$\times$512 feature maps from input 256$\times$256$\times$3 RGB patches.

\subsection*{Loss Functions}

\textbf{Mean Squared Error (MSE)}:
\begin{equation}
\mathcal{L}_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\end{equation}
where $N$ is the number of spatial bins, $y_i$ is the true count, and $\hat{y}_i$ is the predicted count. MSE is differentiable everywhere and assumes Gaussian noise, making it the default for continuous regression tasks.

\textbf{Poisson Negative Log-Likelihood (NLL)}:
\begin{equation}
\mathcal{L}_{\text{Poisson}} = \frac{1}{N} \sum_{i=1}^{N} \left( \hat{y}_i - y_i \log(\hat{y}_i + \epsilon) \right)
\end{equation}
where $\epsilon = 10^{-8}$ prevents $\log(0)$ when $\hat{y}_i = 0$. This is the negative log-likelihood of observing count $y_i$ from a Poisson distribution with rate $\hat{y}_i$. The model predicts the rate parameter (mean of the Poisson), and the loss is minimized when predicted rates match empirical count distributions.

Final layer activation: Linear (unbounded) for both losses, with ReLU applied post-prediction to ensure $\hat{y} \geq 0$ as required for Poisson rates. To account for extreme sparsity in 2$\mu$m data, decoder final layers were initialized with negative bias ($b = -5.0$ for epithelial markers, $b = -3.0$ for housekeeping genes) to match gene-specific zero fractions. This initialization prevents early training collapse by starting predictions near empirical sparsity levels rather than uniform mid-range values.

\subsection*{Training Protocol}

Models were trained using 3-fold cross-validation with patient-level splits to prevent data leakage (each fold: 2 patients training, 1 patient testing). Training hyperparameters: batch size 32, learning rate $10^{-4}$ (AdamW optimizer with weight decay $10^{-5}$), 50 epochs with early stopping (patience=10 on validation SSIM). Data augmentation: random horizontal/vertical flips, 90Â° rotations, color jittering (brightness $\pm$0.2, contrast $\pm$0.2). All models trained on NVIDIA RTX 5090 (24GB VRAM) for 6-12 hours per fold.

\subsection*{Evaluation Metrics}

Primary metric was structural similarity index (SSIM)\cite{Wang2004}:
\begin{equation}
\text{SSIM}(x,y) = \frac{(2\mu_x\mu_y + C_1)(2\sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}
\end{equation}
where $\mu$ denotes mean, $\sigma^2$ variance, $\sigma_{xy}$ covariance, computed over 11$\times$11 windows with Gaussian weighting. Constants $C_1 = (0.01 \cdot L)^2$, $C_2 = (0.03 \cdot L)^2$ with dynamic range $L$ stabilize division. SSIM ranges [0,1] with 1 indicating perfect structural match. SSIM captures luminance, contrast, and structure, making it superior to pixel-wise metrics (MSE, MAE, PCC) for spatial data.

Secondary metrics: Pearson correlation coefficient (PCC), mean absolute error (MAE). Statistical significance assessed via paired t-tests with Bonferroni correction ($\alpha = 0.05/4 = 0.0125$ for 4 models).

\subsection*{Factorial Analysis}

Main effects computed as:
\begin{align}
\text{Effect}_{\text{Loss}} &= \frac{1}{2}\left[(\text{SSIM}_{\text{Hist2ST,Poisson}} + \text{SSIM}_{\text{Img2ST,Poisson}}) - (\text{SSIM}_{\text{Hist2ST,MSE}} + \text{SSIM}_{\text{Img2ST,MSE}})\right] \\
\text{Effect}_{\text{Decoder}} &= \frac{1}{2}\left[(\text{SSIM}_{\text{Hist2ST,Poisson}} + \text{SSIM}_{\text{Hist2ST,MSE}}) - (\text{SSIM}_{\text{Img2ST,Poisson}} + \text{SSIM}_{\text{Img2ST,MSE}})\right]
\end{align}
Relative contributions: Loss = 73\%, Decoder = 27\% of total $\Delta$SSIM.

\subsection*{Code and Data Availability}

Code for training and evaluation is available at \url{https://github.com/vanbelkummax/sparsity-trap-manuscript}. Whole slide image (WSI) spatial predictions for all 50 genes showing MSE vs Poisson comparisons are available at \url{https://github.com/vanbelkummax/mse-vs-poisson-2um-benchmark} in the \texttt{figures/wsi\_improved/} directory. Visium HD data used in this study are from public datasets (colorectal cancer cohorts). Trained model weights will be released upon publication.

\section*{Acknowledgments}

[To be added]

\section*{Author Contributions}

M.V.B. conceived the study, designed experiments, performed analysis, and wrote the manuscript.

\section*{Competing Interests}

The author declares no competing interests.

% Bibliography (Nature numbered style)
\begin{thebibliography}{99}

\bibitem{Moor2022}
Moor, A. E. \& Itzkovitz, S.
Spatial transcriptomics: paving the way for tissue-level systems biology.
\textit{Curr. Opin. Biotechnol.} \textbf{46}, 126--133 (2022).

\bibitem{Moses2022}
Moses, L. \& Pachter, L.
Museum of spatial transcriptomics.
\textit{Nat. Methods} \textbf{19}, 534--546 (2022).

\bibitem{10xGenomics2023}
10x Genomics.
Visium HD Spatial Gene Expression Solution.
\textit{Product Documentation} (2023).

\bibitem{He2020}
He, B. \textit{et al.}
Integrating spatial gene expression and breast tumour morphology via deep learning.
\textit{Nat. Biomed. Eng.} \textbf{4}, 827--834 (2020).

\bibitem{Monjo2022}
Monjo, T. \textit{et al.}
Efficient prediction of a spatial transcriptomics profile better characterizes breast cancer tissue sections without costly experimentation.
\textit{Sci. Rep.} \textbf{12}, 4133 (2022).

\bibitem{Bergenstrahle2022}
Bergenstr\aa hle, J. \textit{et al.}
Super-resolved spatial transcriptomics by deep data fusion.
\textit{Nat. Biotechnol.} \textbf{40}, 476--479 (2022).

\bibitem{Zhu2025survey}
Zhu, J. \textit{et al.}
Computer Vision Methods for Spatial Transcriptomics: A Survey.
\textit{bioRxiv} 2025.10.13.682148 (2025).

\bibitem{Huo2025img2st}
Zhu, J. \textit{et al.}
Img2ST-Net: efficient high-resolution spatial omics prediction from whole-slide histology images via fully convolutional image-to-image learning.
\textit{J. Med. Imaging} \textbf{12}, 061410 (2025).

\bibitem{Sarkar2024count}
Sarkar, H. \textit{et al.}
A count-based model for delineating cell-cell interactions in spatial transcriptomics data.
\textit{Genome Biol.} \textbf{25}, 182 (2024).

\bibitem{Sarkar2025gaston}
Sarkar, H. \& Srivastava, A.
Mapping the topography of spatial gene expression with interpretable deep learning.
\textit{Nat. Methods} \textbf{22}, 104--114 (2025).

\bibitem{Sarkar2023gaston}
Sarkar, H. \& Srivastava, A.
Mapping the topography of spatial gene expression with interpretable deep learning.
\textit{Cell Syst.} \textbf{14}, 1--14 (2023).

\bibitem{Sarkar2025siid}
Sarkar, H. \textit{et al.}
Joint imputation and deconvolution of gene expression across spatial transcriptomics platforms.
\textit{bioRxiv} 2025.01.15.627841 (2025).

\bibitem{Love2014}
Love, M. I., Huber, W. \& Anders, S.
Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.
\textit{Genome Biol.} \textbf{15}, 550 (2014).

\bibitem{Robinson2010}
Robinson, M. D., McCarthy, D. J. \& Smyth, G. K.
edgeR: a Bioconductor package for differential expression analysis of digital gene expression data.
\textit{Bioinformatics} \textbf{26}, 139--140 (2010).

\bibitem{Hafemeister2019}
Hafemeister, C. \& Satija, R.
Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression.
\textit{Genome Biol.} \textbf{20}, 296 (2019).

\bibitem{Dejea2018}
Dejea, C. M. \textit{et al.}
Patients with familial adenomatous polyposis harbor colonic biofilms containing tumorigenic bacteria.
\textit{Science} \textbf{359}, 592--597 (2018).

\bibitem{Rubinstein2013}
Rubinstein, M. R. \textit{et al.}
Fusobacterium nucleatum promotes colorectal carcinogenesis by modulating E-cadherin/$\beta$-catenin signaling via its FadA adhesin.
\textit{Cell Host Microbe} \textbf{14}, 195--206 (2013).

\bibitem{Vogelstein2024virchow}
Vogelstein, E. J. \textit{et al.}
A foundation model for clinical-grade computational pathology and rare cancers detection.
\textit{Nat. Med.} \textbf{30}, 2924--2935 (2024).

\bibitem{Wolf2018}
Wolf, F. A., Angerer, P. \& Theis, F. J.
SCANPY: large-scale single-cell gene expression data analysis.
\textit{Genome Biol.} \textbf{19}, 15 (2018).

\bibitem{Wang2004}
Wang, Z., Bovik, A. C., Sheikh, H. R. \& Simoncelli, E. P.
Image quality assessment: from error visibility to structural similarity.
\textit{IEEE Trans. Image Process.} \textbf{13}, 600--612 (2004).

\bibitem{Saka2019}
Saka, S. K. \textit{et al.}
Immuno-SABER enables highly multiplexed and amplified protein imaging in tissues.
\textit{Nat. Biotechnol.} \textbf{37}, 1080--1090 (2019).

\bibitem{Kelley2018}
Kelley, D. R. \textit{et al.}
Sequential regulatory activity prediction across chromosomes with convolutional neural networks.
\textit{Genome Res.} \textbf{28}, 739--750 (2018).

\bibitem{Pachitariu2016}
Pachitariu, M., Stringer, C. \& Harris, K. D.
Robustness of spike deconvolution for neuronal calcium imaging.
\textit{J. Neurosci.} \textbf{36}, 7625--7639 (2016).

\bibitem{Lau2022}
Peng, Z. \textit{et al.}
Spatial transcriptomics atlas reveals the crosstalk between cancer-associated fibroblasts and tumor microenvironment components in colorectal cancer.
\textit{J. Transl. Med.} \textbf{20}, 302 (2022).

\end{thebibliography}

\end{document}
